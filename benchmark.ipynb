{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基准测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们测试：\n",
    "* pymatching\n",
    "* beliefmatching\n",
    "* stimbposd\n",
    "* MLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入STIM含噪线路数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stim\n",
    "\n",
    "def read_circuit(d : int, r : int)->stim.Circuit:\n",
    "    \"\"\"根据相对路径, 读取stim格式的噪声电路.\n",
    "\n",
    "    Args:\n",
    "        d (int): 码矩\n",
    "        r (int): 轮次\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    if d==3:\n",
    "        if r<10:\n",
    "            circuit_noisy = stim.Circuit.from_file(f\"./data/surface_code_bZ_d3_r0{r}_center_3_5/circuit_noisy.stim\")\n",
    "        else:\n",
    "            circuit_noisy = stim.Circuit.from_file(f\"./data/surface_code_bZ_d3_r{r}_center_3_5/circuit_noisy.stim\")\n",
    "    elif d==5:\n",
    "        if r<10:\n",
    "            circuit_noisy = stim.Circuit.from_file(f\"./data/surface_code_bZ_d5_r0{r}_center_5_5/circuit_noisy.stim\")\n",
    "        else:\n",
    "            circuit_noisy = stim.Circuit.from_file(f\"./data/surface_code_bZ_d5_r{r}_center_5_5/circuit_noisy.stim\")    \n",
    "    return circuit_noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取噪声模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy_circuits = [read_circuit(d,r) for d in distances for r in rounds]\n",
    "noisy_circuits = [read_circuit(3, 1), read_circuit(3, 3), read_circuit(5, 1), read_circuit(5, 3)]\n",
    "detector_error_models = [c.detector_error_model(flatten_loops=True) for c in noisy_circuits]\n",
    "decomposed_detector_error_models = [c.detector_error_model(decompose_errors=True, flatten_loops=True) for c in noisy_circuits]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面仅仅说明如何读取文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基准测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyMatching: 0.084\n",
      "BP-Matching: 0.0744\n",
      "BP-OSD: 0.0731\n",
      "MWPM time: 0.010591983795166016s per 10000 shots\n",
      "BM time: 0.9978463649749756s per 10000 shots\n",
      "BP OSD time: 5.1471946239471436s per 10000 shots\n",
      "------benchmark finish------\n",
      "PyMatching: 0.0846\n",
      "BP-Matching: 0.0772\n",
      "BP-OSD: 0.0759\n",
      "MWPM time: 0.010437250137329102s per 10000 shots\n",
      "BM time: 1.0645911693572998s per 10000 shots\n",
      "BP OSD time: 5.097985506057739s per 10000 shots\n",
      "------benchmark finish------\n",
      "PyMatching: 0.0848\n",
      "BP-Matching: 0.0764\n",
      "BP-OSD: 0.074\n",
      "MWPM time: 0.01000213623046875s per 10000 shots\n",
      "BM time: 1.0115976333618164s per 10000 shots\n",
      "BP OSD time: 5.233927965164185s per 10000 shots\n",
      "------benchmark finish------\n",
      "PyMatching: 0.0849\n",
      "BP-Matching: 0.0789\n",
      "BP-OSD: 0.0779\n",
      "MWPM time: 0.010003805160522461s per 10000 shots\n",
      "BM time: 1.0527315139770508s per 10000 shots\n",
      "BP OSD time: 5.27271842956543s per 10000 shots\n",
      "------benchmark finish------\n",
      "PyMatching: 0.0841\n",
      "BP-Matching: 0.0768\n",
      "BP-OSD: 0.0758\n",
      "MWPM time: 0.012002706527709961s per 10000 shots\n",
      "BM time: 1.0365290641784668s per 10000 shots\n",
      "BP OSD time: 5.085673809051514s per 10000 shots\n",
      "------benchmark finish------\n",
      "PyMatching: 0.0811\n",
      "BP-Matching: 0.074\n",
      "BP-OSD: 0.0741\n",
      "MWPM time: 0.011004209518432617s per 10000 shots\n",
      "BM time: 1.1007912158966064s per 10000 shots\n",
      "BP OSD time: 5.325810670852661s per 10000 shots\n",
      "------benchmark finish------\n",
      "PyMatching: 0.0763\n",
      "BP-Matching: 0.0696\n",
      "BP-OSD: 0.0688\n",
      "MWPM time: 0.01050877571105957s per 10000 shots\n",
      "BM time: 1.0399632453918457s per 10000 shots\n",
      "BP OSD time: 5.081835985183716s per 10000 shots\n",
      "------benchmark finish------\n",
      "PyMatching: 0.0805\n",
      "BP-Matching: 0.0724\n",
      "BP-OSD: 0.0716\n",
      "MWPM time: 0.01101541519165039s per 10000 shots\n",
      "BM time: 0.9625353813171387s per 10000 shots\n",
      "BP OSD time: 4.906263113021851s per 10000 shots\n",
      "------benchmark finish------\n",
      "PyMatching: 0.0851\n",
      "BP-Matching: 0.077\n",
      "BP-OSD: 0.0757\n",
      "MWPM time: 0.010015726089477539s per 10000 shots\n",
      "BM time: 1.0101032257080078s per 10000 shots\n",
      "BP OSD time: 5.1994829177856445s per 10000 shots\n",
      "------benchmark finish------\n",
      "PyMatching: 0.0812\n",
      "BP-Matching: 0.0709\n",
      "BP-OSD: 0.0716\n",
      "MWPM time: 0.012996912002563477s per 10000 shots\n",
      "BM time: 1.0251197814941406s per 10000 shots\n",
      "BP OSD time: 5.047726631164551s per 10000 shots\n",
      "------benchmark finish------\n",
      "0.08266 0.07476 0.07385\n"
     ]
    }
   ],
   "source": [
    "import pymatching\n",
    "from beliefmatching import BeliefMatching\n",
    "from stimbposd import BPOSD\n",
    "\n",
    "from MLD import MaxLikelihoodDecoder\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from typing import List, Union, Tuple\n",
    "\n",
    "import time\n",
    "\n",
    "def tuple_syndromes_2_str_syndromes(tuples_list):\n",
    "    string_list = [''.join(map(str, tpl)) for tpl in tuples_list]\n",
    "    return string_list\n",
    "\n",
    "def array_syndromes_2_str_syndromes(tuples_array):\n",
    "    # 将数组转换为字符串数组\n",
    "    return np.array([''.join(map(str, tpl)) for tpl in tuples_array])\n",
    "    # return np.char.join('', tuples_array.astype(str))\n",
    "\n",
    "def experiment_benchmark_decoder(d: int, r: int, num_shots: int, seed = int)-> Tuple[List[int], np.array]:\n",
    "    # 控制问题的规模\n",
    "    ## 读取circuit\n",
    "    # print(f\"distance: {d}, round: {r}\")\n",
    "    noisy_circuit = read_circuit(d,r)\n",
    "    detector_error_model = noisy_circuit.detector_error_model(flatten_loops=True)\n",
    "    detector_number = detector_error_model.num_detectors\n",
    "    decomposed_detector_error_model = noisy_circuit.detector_error_model(decompose_errors = True)\n",
    "    # print(f\"detector number: {detector_number}\")\n",
    "    # print(f\"detector error model: {detector_error_model}\")\n",
    "    # print(f\"decomposed detector error model: {decomposed_detector_error_model}\")\n",
    "    \n",
    "    # 配置解码器\n",
    "    ## MLD\n",
    "    mld = MaxLikelihoodDecoder(detector_error_model = detector_error_model)\n",
    "    ## MWPM\n",
    "    mwpm = pymatching.Matching.from_detector_error_model(decomposed_detector_error_model)\n",
    "    ## BP-Matching\n",
    "    bm = BeliefMatching(noisy_circuit, max_bp_iters=20)\n",
    "    ## BP-OSD    \n",
    "    bposd = BPOSD(detector_error_model, max_bp_iters=20)\n",
    "    \n",
    "    # 随机采样\n",
    "    sampler = noisy_circuit.compile_detector_sampler(seed = seed)\n",
    "    syndromes_array = sampler.sample(shots=num_shots, append_observables=True)\n",
    "    # 数据分离\n",
    "    syndrome_number = noisy_circuits[0].detector_error_model().num_detectors\n",
    "    shots, observables =  syndromes_array[:, :detector_number], syndromes_array[:, detector_number:]\n",
    "    # mld输入数据\n",
    "    # mld_syndrome_str = array_syndromes_2_str_syndromes(np.array(syndromes_array, dtype=int))\n",
    "    \n",
    "    # print(\"------sampler finish------\")\n",
    "    \n",
    "    # 解码算法\n",
    "    ## MLD\n",
    "    # mld_start_time = time.time()\n",
    "    # mld_predicted_observables = mld.decode(mld_syndrome_str)\n",
    "    # mld_end_time = time.time()\n",
    "    \n",
    "    # print(\"------mld finish------\")\n",
    "    ## PyMatching (MWPM)\n",
    "    mwpm_start_time = time.time()\n",
    "    mwpm_predicted_observables = mwpm.decode_batch(shots)\n",
    "    mwpm_end_time = time.time()\n",
    "    \n",
    "    # print(\"------pymatching finish------\")\n",
    "    ## BP-Matching\n",
    "    bm_start_time = time.time()\n",
    "    bm_predicted_observables = bm.decode_batch(shots)\n",
    "    bm_end_time = time.time()\n",
    "    \n",
    "    ## BP-OSD 解码\n",
    "    bposd_start_time = time.time()\n",
    "    bposd_predicted_observables = bposd.decode_batch(shots)\n",
    "    bposd_end_time = time.time()\n",
    "    # print(\"------BP-OSD finish------\")\n",
    "    \n",
    "    # 基于mld解码得到的逻辑错误率应该为：\n",
    "    # mld_num_mistakes = np.sum(np.any(mld_predicted_observables != observables, axis=1))\n",
    "    mwpm_num_mistakes = np.sum(np.any(mwpm_predicted_observables != observables, axis=1))\n",
    "    bm_num_mistakes = np.sum(np.any(bm_predicted_observables != observables, axis=1))\n",
    "    bposd_num_mistakes = np.sum(np.any(bposd_predicted_observables != observables, axis=1))\n",
    "    \n",
    "    # mld_logical_probability = mld_num_mistakes/num_shots\n",
    "    mwpm_logical_probability = mwpm_num_mistakes/num_shots\n",
    "    bm_logical_probability = bm_num_mistakes/num_shots\n",
    "    bposd_logical_probability = bposd_num_mistakes/num_shots\n",
    "    \n",
    "    # print(\"------compute logical error finish------\")\n",
    "    \n",
    "    # print(f\"MLD: {mld_logical_probability}\")\n",
    "    print(f\"PyMatching: {mwpm_logical_probability}\")\n",
    "    print(f\"BP-Matching: {bm_logical_probability}\")\n",
    "    print(f\"BP-OSD: {bposd_logical_probability}\")\n",
    "    \n",
    "    # print(f\"MLD time: {mld_end_time - mld_start_time}s per {num_shots} shots\")\n",
    "    print(f\"MWPM time: {mwpm_end_time - mwpm_start_time}s per {num_shots} shots\")\n",
    "    print(f\"BM time: {bm_end_time - bm_start_time}s per {num_shots} shots\")\n",
    "    print(f\"BP OSD time: {bposd_end_time - bposd_start_time}s per {num_shots} shots\")\n",
    "    \n",
    "    print(\"------benchmark finish------\")\n",
    "    \n",
    "    return mwpm_logical_probability, bm_logical_probability, bposd_logical_probability\n",
    "\n",
    "mwpm_result = 0\n",
    "bm_result = 0\n",
    "bposd_result = 0\n",
    "for i in range(10):\n",
    "    mwpm_logical_probability, bm_logical_probability, bposd_logical_probability = experiment_benchmark_decoder(d=3, r=3, num_shots= 10000, seed=i)\n",
    "    mwpm_result += mwpm_logical_probability\n",
    "    bm_result += bm_logical_probability\n",
    "    bposd_result += bposd_logical_probability\n",
    "print(mwpm_result/10, bm_result/10, bposd_result/10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLD time: 40.80648636817932s per 30000 shots\n",
    "MWPM time: 0.006999969482421875s per 30000 shots\n",
    "BM time: 0.5118021965026855s per 30000 shots\n",
    "BP OSD time: 0.45923829078674316s per 30000 shots\n",
    "\n",
    "MLD time: 14.013275861740112s per 10000 shots\n",
    "MWPM time: 0.0030450820922851562s per 10000 shots\n",
    "BM time: 0.16950583457946777s per 10000 shots\n",
    "BP OSD time: 0.17462468147277832s per 10000 shots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLD的方法，利用另一种方式来计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def experiment_ml_decoder(d: int, r: int, max_syndrome_number: Union[int, None] = None)-> Tuple[List[int], np.array]:\n",
    "#     # 控制问题的规模\n",
    "#     ## 读取circuit\n",
    "#     print(f\"distance: {d}, round: {r}\")\n",
    "#     noisy_circuit = read_circuit(d,r)\n",
    "#     detector_error_model = noisy_circuit.detector_error_model()\n",
    "#     detector_number = detector_error_model.num_detectors\n",
    "#     decomposed_detector_error_model = noisy_circuit.detector_error_model(decompose_errors = True)\n",
    "#     print(f\"detector number: {detector_number}\")\n",
    "    \n",
    "#     # ml和matching解码器\n",
    "#     ml_decoder = MaxLikelihoodDecoder(detector_error_model = detector_error_model)\n",
    "        \n",
    "#     possible_syndromes_array: np.ndarray\n",
    "#     possible_syndromes_str: List[str]\n",
    "    \n",
    "#     ## 生成可能的syndrome输入\n",
    "#     if max_syndrome_number is None:\n",
    "#         possible_syndromes_array = np.indices((2,) * detector_number).reshape(detector_number, -1).T\n",
    "#         possible_syndromes_str = array_syndromes_2_str_syndromes(possible_syndromes_array)\n",
    "#     else:\n",
    "#         possible_syndromes_array = np.indices((2,) * detector_number).reshape(detector_number, -1).T[:max_syndrome_number]\n",
    "#         possible_syndromes_str = array_syndromes_2_str_syndromes(possible_syndromes_array)\n",
    "#     # print(possible_syndromes_array, possible_syndromes_str)\n",
    "#     ## 进行MLD解码\n",
    "#     ml_correcation = ml_decoder.decode(possible_syndromes_str)\n",
    "    \n",
    "#     #基于mld解码得到的逻辑错误率应该为：\n",
    "#     mld_logical_probability = ml_decoder.compute_correcation_logical_probability(possible_syndromes_str)\n",
    "#     print(f\"mld_logical_probability: {mld_logical_probability}\")\n",
    "#     print(f\"MLD decoding: {ml_correcation}, type: {type(ml_correcation)}\")\n",
    "#     return mld_logical_probability\n",
    "\n",
    "# mld_logical_probability = experiment_ml_decoder(d=3, r=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mld_logical_probability = experiment_ml_decoder(d=3, r=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016969999999999996"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.16969999999999996/10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017109999999999993"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.17109999999999992/10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017098999999999996"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.17098999999999995/10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pymatching\n",
    "# from beliefmatching import BeliefMatching\n",
    "# from stimbposd import BPOSD\n",
    "\n",
    "# from MLD import MaxLikelihoodDecoder\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# from typing import List, Union, Tuple\n",
    "\n",
    "# import time\n",
    "\n",
    "# def tuple_syndromes_2_str_syndromes(tuples_list):\n",
    "#     string_list = [''.join(map(str, tpl)) for tpl in tuples_list]\n",
    "#     return string_list\n",
    "\n",
    "# def array_syndromes_2_str_syndromes(tuples_array):\n",
    "#     # 将数组转换为字符串数组\n",
    "#     return np.array([''.join(map(str, tpl)) for tpl in tuples_array])\n",
    "#     # return np.char.join('', tuples_array.astype(str))\n",
    "\n",
    "# def experiment_benchmark_decoder(d: int, r: int, num_shots: int, seed = int)-> Tuple[List[int], np.array]:\n",
    "#     # 控制问题的规模\n",
    "#     ## 读取circuit\n",
    "#     # print(f\"distance: {d}, round: {r}\")\n",
    "#     noisy_circuit = read_circuit(d,r)\n",
    "#     detector_error_model = noisy_circuit.detector_error_model(flatten_loops=True)\n",
    "#     detector_number = detector_error_model.num_detectors\n",
    "#     decomposed_detector_error_model = noisy_circuit.detector_error_model(decompose_errors = True)\n",
    "#     # print(f\"detector number: {detector_number}\")\n",
    "#     # print(f\"detector error model: {detector_error_model}\")\n",
    "#     # print(f\"decomposed detector error model: {decomposed_detector_error_model}\")\n",
    "    \n",
    "#     # 配置解码器\n",
    "#     ## MLD\n",
    "#     mld = MaxLikelihoodDecoder(detector_error_model = detector_error_model)\n",
    "#     ## MWPM\n",
    "#     mwpm = pymatching.Matching.from_detector_error_model(decomposed_detector_error_model)\n",
    "#     ## BP-Matching\n",
    "#     bm = BeliefMatching(noisy_circuit, max_bp_iters=20)\n",
    "#     ## BP-OSD    \n",
    "#     bposd = BPOSD(detector_error_model, max_bp_iters=20)\n",
    "    \n",
    "#     # 随机采样\n",
    "#     sampler = noisy_circuit.compile_detector_sampler(seed = seed)\n",
    "#     syndromes_array = sampler.sample(shots=num_shots, append_observables=True)\n",
    "#     # 数据分离\n",
    "#     syndrome_number = noisy_circuits[0].detector_error_model().num_detectors\n",
    "#     shots, observables =  syndromes_array[:, :detector_number], syndromes_array[:, detector_number:]\n",
    "#     # mld输入数据\n",
    "#     mld_syndrome_str = array_syndromes_2_str_syndromes(np.array(syndromes_array, dtype=int))\n",
    "    \n",
    "#     print(\"------sampler finish------\")\n",
    "    \n",
    "#     # 解码算法\n",
    "#     ## MLD\n",
    "#     mld_start_time = time.time()\n",
    "#     mld_predicted_observables = mld.decode(mld_syndrome_str)\n",
    "#     mld_end_time = time.time()\n",
    "    \n",
    "#     print(\"------mld finish------\")\n",
    "#     ## PyMatching (MWPM)\n",
    "#     mwpm_start_time = time.time()\n",
    "#     mwpm_predicted_observables = mwpm.decode_batch(shots)\n",
    "#     mwpm_end_time = time.time()\n",
    "    \n",
    "#     print(\"------pymatching finish------\")\n",
    "#     ## BP-Matching\n",
    "#     bm_start_time = time.time()\n",
    "#     bm_predicted_observables = bm.decode_batch(shots)\n",
    "#     bm_end_time = time.time()\n",
    "    \n",
    "#     ## BP-OSD 解码\n",
    "#     bposd_start_time = time.time()\n",
    "#     bposd_predicted_observables = bposd.decode_batch(shots)\n",
    "#     bposd_end_time = time.time()\n",
    "#     print(\"------BP-OSD finish------\")\n",
    "    \n",
    "#     # 基于mld解码得到的逻辑错误率应该为：\n",
    "#     mld_num_mistakes = np.sum(np.any(mld_predicted_observables != observables, axis=1))\n",
    "#     mwpm_num_mistakes = np.sum(np.any(mwpm_predicted_observables != observables, axis=1))\n",
    "#     bm_num_mistakes = np.sum(np.any(bm_predicted_observables != observables, axis=1))\n",
    "#     bposd_num_mistakes = np.sum(np.any(bposd_predicted_observables != observables, axis=1))\n",
    "    \n",
    "#     mld_logical_probability = mld_num_mistakes/num_shots\n",
    "#     mwpm_logical_probability = mwpm_num_mistakes/num_shots\n",
    "#     bm_logical_probability = bm_num_mistakes/num_shots\n",
    "#     bposd_logical_probability = bposd_num_mistakes/num_shots\n",
    "    \n",
    "#     print(\"------compute logical error finish------\")\n",
    "    \n",
    "#     print(f\"MLD: {mld_logical_probability}\")\n",
    "#     print(f\"PyMatching: {mwpm_logical_probability}\")\n",
    "#     print(f\"BP-Matching: {bm_logical_probability}\")\n",
    "#     print(f\"BP-OSD: {bposd_logical_probability}\")\n",
    "    \n",
    "#     print(f\"MLD time: {mld_end_time - mld_start_time}s per {num_shots} shots\")\n",
    "#     print(f\"MWPM time: {mwpm_end_time - mwpm_start_time}s per {num_shots} shots\")\n",
    "#     print(f\"BM time: {bm_end_time - bm_start_time}s per {num_shots} shots\")\n",
    "#     print(f\"BP OSD time: {bposd_end_time - bposd_start_time}s per {num_shots} shots\")\n",
    "    \n",
    "#     print(\"------benchmark finish------\")\n",
    "    \n",
    "#     return mwpm_logical_probability, bm_logical_probability, bposd_logical_probability\n",
    "\n",
    "# mwpm_result = 0\n",
    "# bm_result = 0\n",
    "# bposd_result = 0\n",
    "# for i in range(10):\n",
    "#     mwpm_logical_probability, bm_logical_probability, bposd_logical_probability = experiment_benchmark_decoder(d=5, r=1, num_shots= 30, seed=i)\n",
    "#     mwpm_result += mwpm_logical_probability\n",
    "#     bm_result += bm_logical_probability\n",
    "#     bposd_result += bposd_logical_probability\n",
    "# print(mwpm_result/10, bm_result/10, bposd_result/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mwpm_logical_probability, bm_logical_probability, bposd_logical_probability = experiment_benchmark_decoder(d=3, r=3, num_shots= 10, seed=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyMatching: 0.0084\n",
      "BP-Matching: 0.0084\n",
      "BP-OSD: 0.0086\n",
      "MWPM time: 0.007239818572998047s per 10000 shots\n",
      "BM time: 0.316497802734375s per 10000 shots\n",
      "BP OSD time: 0.5381124019622803s per 10000 shots\n",
      "------benchmark finish------\n",
      "PyMatching: 0.0084\n",
      "BP-Matching: 0.0086\n",
      "BP-OSD: 0.0081\n",
      "MWPM time: 0.008001327514648438s per 10000 shots\n",
      "BM time: 0.32384204864501953s per 10000 shots\n",
      "BP OSD time: 0.5659589767456055s per 10000 shots\n",
      "------benchmark finish------\n",
      "PyMatching: 0.008\n",
      "BP-Matching: 0.0079\n",
      "BP-OSD: 0.0081\n",
      "MWPM time: 0.0076007843017578125s per 10000 shots\n",
      "BM time: 0.32798075675964355s per 10000 shots\n",
      "BP OSD time: 0.579092264175415s per 10000 shots\n",
      "------benchmark finish------\n",
      "PyMatching: 0.0077\n",
      "BP-Matching: 0.0073\n",
      "BP-OSD: 0.0075\n",
      "MWPM time: 0.008001327514648438s per 10000 shots\n",
      "BM time: 0.3211379051208496s per 10000 shots\n",
      "BP OSD time: 0.5552799701690674s per 10000 shots\n",
      "------benchmark finish------\n",
      "PyMatching: 0.0073\n",
      "BP-Matching: 0.007\n",
      "BP-OSD: 0.0072\n",
      "MWPM time: 0.00899052619934082s per 10000 shots\n",
      "BM time: 0.3090250492095947s per 10000 shots\n",
      "BP OSD time: 0.5354058742523193s per 10000 shots\n",
      "------benchmark finish------\n",
      "PyMatching: 0.0071\n",
      "BP-Matching: 0.0066\n",
      "BP-OSD: 0.0072\n",
      "MWPM time: 0.008393049240112305s per 10000 shots\n",
      "BM time: 0.31406497955322266s per 10000 shots\n",
      "BP OSD time: 0.5164365768432617s per 10000 shots\n",
      "------benchmark finish------\n",
      "PyMatching: 0.0065\n",
      "BP-Matching: 0.0063\n",
      "BP-OSD: 0.0063\n",
      "MWPM time: 0.00800323486328125s per 10000 shots\n",
      "BM time: 0.3111739158630371s per 10000 shots\n",
      "BP OSD time: 0.5410382747650146s per 10000 shots\n",
      "------benchmark finish------\n",
      "PyMatching: 0.0055\n",
      "BP-Matching: 0.005\n",
      "BP-OSD: 0.0055\n",
      "MWPM time: 0.00699615478515625s per 10000 shots\n",
      "BM time: 0.31087160110473633s per 10000 shots\n",
      "BP OSD time: 0.5548837184906006s per 10000 shots\n",
      "------benchmark finish------\n",
      "PyMatching: 0.0061\n",
      "BP-Matching: 0.006\n",
      "BP-OSD: 0.0061\n",
      "MWPM time: 0.008028507232666016s per 10000 shots\n",
      "BM time: 0.3036501407623291s per 10000 shots\n",
      "BP OSD time: 0.5050163269042969s per 10000 shots\n",
      "------benchmark finish------\n",
      "PyMatching: 0.0092\n",
      "BP-Matching: 0.0087\n",
      "BP-OSD: 0.0086\n",
      "MWPM time: 0.009224176406860352s per 10000 shots\n",
      "BM time: 0.364729642868042s per 10000 shots\n",
      "BP OSD time: 0.5389807224273682s per 10000 shots\n",
      "------benchmark finish------\n",
      "0.00742 0.007180000000000001 0.007319999999999998\n"
     ]
    }
   ],
   "source": [
    "import pymatching\n",
    "from beliefmatching import BeliefMatching\n",
    "from stimbposd import BPOSD\n",
    "\n",
    "from MLD import MaxLikelihoodDecoder\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from typing import List, Union, Tuple\n",
    "\n",
    "import time\n",
    "\n",
    "def tuple_syndromes_2_str_syndromes(tuples_list):\n",
    "    string_list = [''.join(map(str, tpl)) for tpl in tuples_list]\n",
    "    return string_list\n",
    "\n",
    "def array_syndromes_2_str_syndromes(tuples_array):\n",
    "    # 将数组转换为字符串数组\n",
    "    return np.array([''.join(map(str, tpl)) for tpl in tuples_array])\n",
    "    # return np.char.join('', tuples_array.astype(str))\n",
    "\n",
    "def experiment_benchmark_decoder(d: int, r: int, num_shots: int, seed = int)-> Tuple[List[int], np.array]:\n",
    "    # 控制问题的规模\n",
    "    ## 读取circuit\n",
    "    # print(f\"distance: {d}, round: {r}\")\n",
    "    noisy_circuit = read_circuit(d,r)\n",
    "    detector_error_model = noisy_circuit.detector_error_model(flatten_loops=True)\n",
    "    detector_number = detector_error_model.num_detectors\n",
    "    decomposed_detector_error_model = noisy_circuit.detector_error_model(decompose_errors = True)\n",
    "    # print(f\"detector number: {detector_number}\")\n",
    "    # print(f\"detector error model: {detector_error_model}\")\n",
    "    # print(f\"decomposed detector error model: {decomposed_detector_error_model}\")\n",
    "    \n",
    "    # 配置解码器\n",
    "    ## MLD\n",
    "    mld = MaxLikelihoodDecoder(detector_error_model = detector_error_model)\n",
    "    ## MWPM\n",
    "    mwpm = pymatching.Matching.from_detector_error_model(decomposed_detector_error_model)\n",
    "    ## BP-Matching\n",
    "    bm = BeliefMatching(noisy_circuit, max_bp_iters=20)\n",
    "    ## BP-OSD    \n",
    "    bposd = BPOSD(detector_error_model, max_bp_iters=20)\n",
    "    \n",
    "    # 随机采样\n",
    "    sampler = noisy_circuit.compile_detector_sampler(seed = seed)\n",
    "    syndromes_array = sampler.sample(shots=num_shots, append_observables=True)\n",
    "    # 数据分离\n",
    "    syndrome_number = noisy_circuits[0].detector_error_model().num_detectors\n",
    "    shots, observables =  syndromes_array[:, :detector_number], syndromes_array[:, detector_number:]\n",
    "    # mld输入数据\n",
    "    # mld_syndrome_str = array_syndromes_2_str_syndromes(np.array(syndromes_array, dtype=int))\n",
    "    \n",
    "    # print(\"------sampler finish------\")\n",
    "    \n",
    "    # 解码算法\n",
    "    ## MLD\n",
    "    # mld_start_time = time.time()\n",
    "    # mld_predicted_observables = mld.decode(mld_syndrome_str)\n",
    "    # mld_end_time = time.time()\n",
    "    \n",
    "    # print(\"------mld finish------\")\n",
    "    ## PyMatching (MWPM)\n",
    "    mwpm_start_time = time.time()\n",
    "    mwpm_predicted_observables = mwpm.decode_batch(shots)\n",
    "    mwpm_end_time = time.time()\n",
    "    \n",
    "    # print(\"------pymatching finish------\")\n",
    "    ## BP-Matching\n",
    "    bm_start_time = time.time()\n",
    "    bm_predicted_observables = bm.decode_batch(shots)\n",
    "    bm_end_time = time.time()\n",
    "    \n",
    "    ## BP-OSD 解码\n",
    "    bposd_start_time = time.time()\n",
    "    bposd_predicted_observables = bposd.decode_batch(shots)\n",
    "    bposd_end_time = time.time()\n",
    "    # print(\"------BP-OSD finish------\")\n",
    "    \n",
    "    # 基于mld解码得到的逻辑错误率应该为：\n",
    "    # mld_num_mistakes = np.sum(np.any(mld_predicted_observables != observables, axis=1))\n",
    "    mwpm_num_mistakes = np.sum(np.any(mwpm_predicted_observables != observables, axis=1))\n",
    "    bm_num_mistakes = np.sum(np.any(bm_predicted_observables != observables, axis=1))\n",
    "    bposd_num_mistakes = np.sum(np.any(bposd_predicted_observables != observables, axis=1))\n",
    "    \n",
    "    # mld_logical_probability = mld_num_mistakes/num_shots\n",
    "    mwpm_logical_probability = mwpm_num_mistakes/num_shots\n",
    "    bm_logical_probability = bm_num_mistakes/num_shots\n",
    "    bposd_logical_probability = bposd_num_mistakes/num_shots\n",
    "    \n",
    "    # print(\"------compute logical error finish------\")\n",
    "    \n",
    "    # print(f\"MLD: {mld_logical_probability}\")\n",
    "    print(f\"PyMatching: {mwpm_logical_probability}\")\n",
    "    print(f\"BP-Matching: {bm_logical_probability}\")\n",
    "    print(f\"BP-OSD: {bposd_logical_probability}\")\n",
    "    \n",
    "    # print(f\"MLD time: {mld_end_time - mld_start_time}s per {num_shots} shots\")\n",
    "    print(f\"MWPM time: {mwpm_end_time - mwpm_start_time}s per {num_shots} shots\")\n",
    "    print(f\"BM time: {bm_end_time - bm_start_time}s per {num_shots} shots\")\n",
    "    print(f\"BP OSD time: {bposd_end_time - bposd_start_time}s per {num_shots} shots\")\n",
    "    \n",
    "    print(\"------benchmark finish------\")\n",
    "    \n",
    "    return mwpm_logical_probability, bm_logical_probability, bposd_logical_probability\n",
    "\n",
    "mwpm_result = 0\n",
    "bm_result = 0\n",
    "bposd_result = 0\n",
    "for i in range(10):\n",
    "    mwpm_logical_probability, bm_logical_probability, bposd_logical_probability = experiment_benchmark_decoder(d=5, r=1, num_shots= 10000, seed=i)\n",
    "    mwpm_result += mwpm_logical_probability\n",
    "    bm_result += bm_logical_probability\n",
    "    bposd_result += bposd_logical_probability\n",
    "print(mwpm_result/10, bm_result/10, bposd_result/10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decoding_benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
